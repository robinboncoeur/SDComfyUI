################
About SD-ComfyUI
################

********
Foreword
********

.. image:: http://www.tightbytes.com/art/images/Cui/23/LesAmies08a.png
    :width: 600px
    
These pages are all about sharing what I've sort-of picked up using ComfyUI and Stable Diffusion.

I have rather gravitated towards ComfyUI as my Stable Diffusion interface because of its flexibility through the use of nodes. These pages reflect my current uderstanding and use of this interface. I still have much to learn and explore in this rapidly expanding world of AI-based graphics. Hope my meanderings prove useful to someone.



**********
Background
**********

=============
First Efforts
=============

.. image:: https://www.tightbytes.com/art/images/Cui/23/Charlotte.png
    :width: 400px

Quick history:

    * MidJourney... very quickly created characters such as Charlotte. It was so satisfying that I paid for a subscription. However, the characters all began to look very similar.
    * LeonardoAI... Subsequently, this produced a significantly broader variety of individual faces. The key character 'Victoria' evolved in Leonardo.
    * Discovered Stable Diffusion and Automatic1111, which opened the door to limitless image/character creation (including NSFW). For this, however, I needed a more powerful graphics card.
    * Purchased the NVidia 3070 (8gig VRAM) card. Note: this card had *only* 8gig of VRAM, where the 3060 had 12, which would have made a better choice.
    * Downloaded and (via Anaconda) installed Automatic1111 web-UI.

========
In A1111
========

.. image:: https://www.tightbytes.com/art/images/Cui/23/Staci-CafeB1.png
    :width: 600px
    
The main objectives:

    * 1-to create as realistic (photo-real) characters as possible
    * 2-create *consistent* characters (back to MidJourney for this)
    * 3-have multiple characters in a scene
    * 4-have those multiple characters be unique (different from each other)
    * 5-have those multiple characters be reproduceable

Was able to achieve 1, 2, 3 and 4. Installed but did not invoke roop - did all Faceswapping in MidJourney.

Discovered ComfyUI, and migrated all activities to ComfyUI.



****************************
Node-based Interface ComfyUI
****************************

===================
Objective Breakdown
===================

I installed ComfyUI in the recommended Python3.10.6 environment which eliminated many obscure Python error messages no one seemed to have an answer to. I reinstalled A1111 the same way: bog-standard Python3.10.6 venv. All models are currently saved in the A1111 folder. As of September, 2023, have cancelled all subscriptions to Leonardo and MidJourney: roop is very straightforward and easy to accomplish in ComfyUI.

The main objectives, current as of 7th Oct, 2023, are:

    * 1-to create as realistic (photo-real) characters as possible **[DONE]**
    * 2-create *consistent* characters **[DONE using roop]**
    * 3-have multiple characters in a scene **[DONE]**
    * 4-have those multiple characters be unique and reproduceable **[DONE dual roop]**
    * 5-characters will be anatomically correct (minimal deformities)
    * 6-have those multiple characters interact (more than just staring blankly)
    * 7-clothe the characters differently
    * 8-develop poses / LoRA / LyCORIS etc


-------------------------
2 - Consistent Characters
-------------------------

.. image:: https://www.tightbytes.com/art/images/Cui/23/Charlotte-Robyn-Library.png
    :width: 400px

The first characters (Charlotte, Victoria, Mabel, etc) were created for an odd little novella I was writing, one that has sort-of stalled as what I started writing seemed, with time, a bit trite and uninspired. They were 'created' in MidJourney and later LeonardoAI, satisfying the 'photoreal' requirement easily. I've since gone to using `This Person Does Not Exist <https://thispersondoesnotexist.com>`_ for reference faces as the features are a lot less airbrushed and produce far more realistic-looking individuals using roop. There is  one carefully GIMPed real person reference image for a persona in some of my images. 


-----------------------
3 - Multiple Characters
-----------------------

The length and detail of the prompt very much affects how consistently I can get two characters to appear. Too much emphasis on a detail results in one person to appear instead of two, regardless of whether I enclose the phrase '2 women' in parentheses. Removing detail fixes the problem.


------------------------------------
4 - Unique, reproduceable characters
------------------------------------

Generally speaking, the same conditions that result in only one figure appearing where two were asked for account for roop working consistently. I've had Comfy assigned my first face to a tertiary individual in the image (very much a background figure) and so the first character receives the second face and none is assigned to the second charcter at all:

.. image:: https://www.tightbytes.com/art/images/Cui/23/Cui-3rdChar.png
    :width: 400px

In this image, the first face was given to the obscure person on the couch on the left of the picture, the second figure - in the far-too-short skirt - was given the second face by roop, and the third figure was whatever Comfy / SD had in mind. Note: this brings up another interesting challenge... appropriate attire. Unfortunately, prompting has little effect on the length of skirts or the decollette of the neckline.

So, whilst I do feel this objective has been accomplished, getting consistent results very much depends on shorter, concise prompts. Details may need to come from LoRAs or - newer tech for artists this October - IP Adapters.


------------------------------
5 - Minimal, or no Deformities
------------------------------

While for the most part, facial distortion appears to have been resolved - with the exception of when the faces are in close proximity to each other - hand deformities unfortunately, frustratingly persist:

.. image:: https://www.tightbytes.com/art/images/Cui/23/EnBateau01.png
    :width: 400px

Note the hands (rendered 06.Oct.23) - this is currently my main objective: to consistently render non-deformed limbs, or at least be able to fix deformities via inpainting or something like that.

And yet, in the preceding image, the hands are fine.

**Update: 23.10.08**

The original developer of `ComfyUI's Manager <https://github.com/ltdrdata/ComfyUI-Manager>`_, ltdrdata, has released a video proposing an *automatic* fix to hand deformations. The key node-set to manage all this is contained in his Impact Pack.


-------------------------
6 - Character Interaction
-------------------------

So far (Oct 2023) no real solution has presented itself. Indeed, getting one character to show one expression and the other, something else eludes me. Even getting the characters to look at anything specific is "too-hard basket" stuff at the moment. I can get 'selfie'-style shots galore, and, a la rigeur, two individuals 'discussing' while each sort of looks off into the distance, ostensibly contemplative, but even achieving **that** is inconsistent and really, how much need is there for that sort of pose? Getting consistent interaction remains a thorny problem. I currently can have characters holding hands and 'embrace' but (at least in SD1.5), a more intimate display of affection - i.e., a kiss - tends to distort the faces near the contact point. (Observed 04.Oct.23: *appears to be a* **roop** *thing*).


.. raw:: html

   <hr style="height:8px;border-width:0;color:black;background-color:black">



============================
Node Sets - October Workflow
============================

-----------------------
Nodes affect Objectives
-----------------------

**23.10.08**

I am discovering that, almost as much if not more, prompts - and specifically the injudicious, casual use of keyworks in a prompt, will lead to undesireable outcomes in the final image. For example: I had the phrase "lace-up boots" in a prompt. this resulted in short skirts and lace-topped stockings. Removing this brought the skirt hemline down to more desireable levels and a far better image.

In a good prompt, less is more. Too many words in the negative prompt does absolutely nothing to improve the image and can adversely affect the outcome.

Challenges I have yet to resolve:

    * Camera distance from my subject
    * What the subject is looking at is consistent to the prompt
 

---------
HiRes Fix
---------

**23.10.07**

From Automatic1111, I really missed 'HiRez-Fix'. Well, got that working, sort-of. I *think*. Open to new ideas, particularly if they work:

.. image:: https://www.tightbytes.com/art/images/Cui/23/231007-HiResFix.png
    :width: 600px


**23.10.09**

Thanks to **EndangeredAI** and his excellent videos (linked below), I've had cause to revise the Sampling section of my workflow. Mind you: what was suggested wasn't for HiResFix per se, and it was SDXL-based, so I might look at it again

**Nodal Noodles**

The Efficiency Pack clears up a lot of noodle mess. It includes one LoRA and an empty latent image.


----------
IP Adapter
----------

**23.10.13**

At this juncture, I'm able to render two characters - in this case, women - with consistent faces. Despite the hand fix "module", perhaps because of the proximity of the characters hands can still turn out a bit messy. I'm cycling through the checkpoints to see if one of them does a better job at this. At the moment (1000h) the **Swizz8-BakedVAE-FP16-Pruned** checkpoint appeared initially to produce the best results. However, with subsequent renders limbs were missing and the figures put themselves in impossible poses. 





.. raw:: html

   <hr style="height:4px;border-width:0;color:gray;background-color:gray">



=======================
ComfyUI Tips and Tricks
=======================

The "Unofficial" `Sub-Reddit ComfyUI <https://www.reddit.com/r/comfyui/new/>`_ has proven an amazing resource, more than anywhere else, to be honest. Hope to collect some of the "Tips and Tricks" I pick up here.
 
-------------------
Inserting Node-sets
-------------------

To insert a node-set into a workflow:

    * **save** the node set to insert by highlighing the nodes, and [RtClick] -> 'Save Selected as Template'
    * In the target workflow, [RtClick] -> 'Node Templates' (select the node set)
 
 Caveat: if enclosed in a grouping box, the box is not saved into the template.
 
 Note: templates are stored in the browser's cache. Until recently, there was no GUI-based approach to removing unwanted templates: that has changed.


.. raw:: html
   
   <hr style="height:8px;border-width:0;color:gray;background-color:black">




************************
Media - Social and Other
************************

=============
The IPAdapter
=============

How to use the models, by the Developer: Matt

with **Latent Vision**

.. raw:: html
   
   <iframe width="560" height="315" src="https://www.youtube.com/embed/7m9ZZFU3HWo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


===========================
ComfyUI Nodes: What they Do
===========================

Complete Comfy UI SDXL 1.0 Guide Part 1 - Beginner to Pro Series

with **Endangered AI**

.. raw:: html
   
   <iframe width="560" height="315" src="https://www.youtube.com/embed/39k5e5_kfJ8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


.. raw:: html
   
   <hr style="height:8px;border-width:0;color:black;background-color:gray">



==========================
Posts on SubReddit ComfyUI
==========================

**23.10.07**

Note: *removed this post as it was not as good as those by EndangeredAI*

Different artists, different solutions. You're starting this learning process correctly: simple workflows is the way to go. I'm also finding that the simpler the prompts - positive and negative - the more consistent the output.

I'm be happy to share my workflow (via json-embedded pngs):

    https://tightbytes.com/art/images/Cui/23/ComfyUI_35.png
    https://tightbytes.com/art/images/Cui/23/ComfyUI_40.png

The workflow in both images is identical: it manages two individuals - well, women... haven't worked out how to mix it up with multiple figures yet - in a variety of settings and the faces remain the same. In order to have a play with the workflow, you will need to install:
    * Efficiency Nodes
    * Ultimate SD Upscale
    * ComfyUI roop
    * Checkpoint: epiCRealismSin with add_detail and epiCRealismHelper LoRAs, but those are just my preference - any SD1.5 models will do
    * RgThree's nodes, and probably some other stuff too - CivitAI is a great place to "shop"!  :-)

All of these - and heaps more - can all be installed via 'Manager'. You will need that, of course.

For faces, you can always generate and save a face in Comfy, but I've found that thispersondoesnotexist generates high-detail faces that work quite well with roop. Your mileage may vary, of course.



======================
Stable Diffusion Links
======================

`For Tavern <https://www.chub.ai/characters>`_

`Civit-AI <https://civitai.com/>`_

`OpenPose <https://github.com/CMU-Perceptual-Computing-Lab/openpose>`_

`GPT4All <https://github.com/nomic-ai/gpt4all>`_

`SD Tute <https://unimatrixz.com/blog/latent-space-camera-positions-developing-prompts/>`_

`SD Guide <https://stable-diffusion-art.com/prompt-guide/>`_

`SD 1.5 Download - needs 16gig card <https://rentry.org/sdmodels#stable-diffusion-v15-81761151-a9263745>`_

`SD 1.5 Download-HuggingFace <https://huggingface.co/runwayml/stable-diffusion-v1-5>`_

`SD 1.5 Hardware <https://decentralizedcreator.com/stable-diffusion-pc-hardware-requirement-detailed-guide/?utm_content=cmp-true>`_

`NSFW Gen <https://metaroids.com/lists/adult-ai-art-tools-that-can-generate-nsfw-ai-images/>`_

`Downloading from HuggingFace <https://huggingface.co/docs/hub/models-downloading>`_

`More on downloading <https://huggingface.co/docs/huggingface_hub/guides/download>`_

`HuggingFace Hub <https://github.com/huggingface/huggingface_hub>`_

`PlanetSuzy SD Guide <http://www.planetsuzy.org/t1098045-p8-stablediffusion-ai-part-two.html>`_




.. raw:: html
   
   <hr style="height:16px;border-width:0;color:black;background-color:black">







*************************************
Reminders [to Myself] of Sphinx Stuff
*************************************

=============
Inline images
=============

For externally-stored images (most will be stored on Tightbytes, for my pages)::

	* .. image:: http://www.tightbytes.com/Music/CReinecke/CReinecke1890.jpg

and for those stored with the data files::

	* .. image:: ../images/blAltRtClick01.png



======================
Embedded YouTube Video
======================

This code::

   .. raw:: html
   
   <iframe width="560" height="315" src="https://www.youtube.com/embed/123xxxXXXyZ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

   <hr style="height:4px;border-width:0;color:gray;background-color:gray">

Should have 11 characters::

	3LbsmS5TJXA
	123xxxXXXyZ

Key to note is the difference in the link in the raw html syntax vs the actual youtube link::

	https://www.youtube.com/embed/123xxxXXXyZ
	https://www.youtube.com/watch?v=9USTddwNoXU

Basically, "embed/" instead of "watch?v=".



==============
Embedded Audio
==============

This code::

	.. raw:: html

		<audio controls="controls">
		  <source src="http://tightbytes.com/music/Sketches/Sketch11.mp3" type="audio/wav">
		  Your browser does not support the <code>audio</code> element. 
		</audio>

...produces:

.. raw:: html

    <audio controls="controls">
      <source src="http://tightbytes.com/music/Sketches/Sketch11.mp3" type="audio/wav">
      Your browser does not support the <code>audio</code> element. 
    </audio>

.. raw:: html
   
   <hr style="height:1px;border-width:0;color:gray;background-color:gray">



==========================
Embedded Non-youtube Video
==========================

This code::

	.. raw:: html

	   <iframe width="560" height="315" src="https://tightbytes.com/videos/projects/garden/Aj-SHTrench.mp4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	   
	   |
	   

...produces:

.. raw:: html

   <iframe width="560" height="315" src="https://tightbytes.com/videos/projects/garden/Aj-SHTrench.mp4" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
   
   |


(Note to self: took out  [  autoplay; ] )

.. raw:: html
   
   <hr style="height:1px;border-width:0;color:gray;background-color:gray">



==================
Creating Dotpoints
==================

Once you've decided:

  * Select A.

  * Select B. 

  * To identify C.

  * Finally, click on D.


Note: *setting things to italics like this makes more impact - these have yielded reasonable results. You will almost certainly find better settings, which is the whole point of sharing this*.



================
Links Management
================

Here's a typical example of embedding a link: Blender-for-Mac users, please refer to the `Mac user help <http://blender.stackexchange.com/questions/6173/where-does-console-output-go>`_ page.




==========================
Horizontal Separator Lines
==========================

The code is this (minus the '*')::

	* .. raw:: html
   
   <hr style="height:4px;border-width:0;color:gray;background-color:gray">

...which produces the following grey horizonal bar to help separate sctions (like the one below).

.. raw:: html
   
   <hr style="height:4px;border-width:0;color:gray;background-color:gray">




============
Sphinx Links
============

https://thomas-cokelaer.info/tutorials/sphinx/rest_syntax.html

https://docutils.sourceforge.io/docs/ref/rst/directives.html#images

https://docutils.sourceforge.io/docs/ref/rst/directives.html#container

https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html#table-of-contents

https://docutils.sourceforge.io/docs/ref/doctree.html#classes



************
HTML and CSS
************

Grid for two simple layouts

https://www.youtube.com/watch?v=r1IitKbJRFE

Slide Show

https://www.youtube.com/watch?v=WJERnXiFFug

https://ishadeed.com/article/conditional-css-has-nth-last-child/?utm_source=convertkit&utm_medium=email&utm_campaign=Why+people+use+CSS+frameworks%20-%2010872019

AstroDocs

https://docs.astro.build/en/editor-setup/







